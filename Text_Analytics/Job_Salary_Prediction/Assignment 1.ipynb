{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics - Assignment 1\n",
    "\n",
    "**Group Members** - \n",
    "1. Sagar Chadha\n",
    "2. Ryan Hoff\n",
    "3. Cory Nguyen\n",
    "4. Akhilesh Reddy\n",
    "5. Lu-Hao Kuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                        Title  \\\n",
       "0  12612628  Engineering Systems Analyst   \n",
       "1  12612830      Stress Engineer Glasgow   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "\n",
       "                   LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "0      Dorking, Surrey, Surrey            Dorking          NaN    permanent   \n",
       "1  Glasgow, Scotland, Scotland            Glasgow          NaN    permanent   \n",
       "\n",
       "                        Company          Category                   SalaryRaw  \\\n",
       "0  Gregory Martin International  Engineering Jobs  20000 - 30000/annum 20-30K   \n",
       "1  Gregory Martin International  Engineering Jobs  25000 - 35000/annum 25-35K   \n",
       "\n",
       "   SalaryNormalized        SourceName  \n",
       "0             25000  cv-library.co.uk  \n",
       "1             30000  cv-library.co.uk  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the train_rev1 datafile downloaded from kaggle\n",
    "df = pd.read_csv('Train_rev1.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35222, 149213, 222149, 210308, 200218]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample 2500 rows from the data\n",
    "import random\n",
    "random.seed(1)\n",
    "indices = df.index.values.tolist()\n",
    "\n",
    "random_2500 = random.sample(indices, 2500)\n",
    "\n",
    "random_2500[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68234454</td>\n",
       "      <td>Bar &amp; Leisure Supervisor</td>\n",
       "      <td>Genting Casinos UK is looking for an experienc...</td>\n",
       "      <td>Leicester Leicestershire East Midlands</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genting UK</td>\n",
       "      <td>Hospitality &amp; Catering Jobs</td>\n",
       "      <td>Up to 17,000 per annum</td>\n",
       "      <td>17000</td>\n",
       "      <td>caterer.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70762305</td>\n",
       "      <td>Principal Development Engineer</td>\n",
       "      <td>Principal Development Engineer  RF Microwave /...</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>ATA Recruitment</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>38000 - 45000/annum + 38k - 45k (DOE) + Pensio...</td>\n",
       "      <td>41500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                           Title  \\\n",
       "0  68234454        Bar & Leisure Supervisor   \n",
       "1  70762305  Principal Development Engineer   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Genting Casinos UK is looking for an experienc...   \n",
       "1  Principal Development Engineer  RF Microwave /...   \n",
       "\n",
       "                              LocationRaw LocationNormalized ContractType  \\\n",
       "0  Leicester Leicestershire East Midlands          Leicester          NaN   \n",
       "1                                Scotland           Scotland          NaN   \n",
       "\n",
       "  ContractTime          Company                     Category  \\\n",
       "0          NaN       Genting UK  Hospitality & Catering Jobs   \n",
       "1    permanent  ATA Recruitment             Engineering Jobs   \n",
       "\n",
       "                                           SalaryRaw  SalaryNormalized  \\\n",
       "0                             Up to 17,000 per annum             17000   \n",
       "1  38000 - 45000/annum + 38k - 45k (DOE) + Pensio...             41500   \n",
       "\n",
       "         SourceName  \n",
       "0       caterer.com  \n",
       "1  cv-library.co.uk  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset the imported data on the selected 2500 indices\n",
    "train = df.loc[random_2500, :]\n",
    "train = train.reset_index(drop = True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some problems with the way FullDescription has been encoded\n",
    "def convert_utf8(s):\n",
    "    return str(s)\n",
    "\n",
    "train['FullDescription'] = train['FullDescription'].map(convert_utf8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach - \n",
    "1. Lets first make a corpus of all the descriptions provided to us.\n",
    "2. From this corpus, we will pick up anomalies in the descriptions - urls, numbers, etc. that are of no use to us in terms of predictions.\n",
    "3. We will make lists of these anomalous strings.\n",
    "4. Going back to our dataset, we will clean the descriptions by removing these anomalous strings from the job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a corpus of all the words in the job description\n",
    "corpus = \". \".join(train['FullDescription'].tolist())\n",
    "\n",
    "# tokenize the corpus to get individual words\n",
    "tokens = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice the following  a lot of urls in the text corpus. We should remove these before proceeding.\n",
    "Urls would usually have 'co.uk' in them or '.com' in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all urls in the data\n",
    "weblinks = [w for w in tokens if \".co.uk\" in w]\n",
    "weblinks = weblinks + [w for w in tokens if \".com\" in w] + [w for w in tokens if \"www.\" in w]\n",
    "weblinks = list(set(weblinks))\n",
    "\n",
    "# We also notice a lot of words with '*' characters in them. These are sometimes salary figures that have been hidden to \n",
    "# keep the prediction problem meaningful. Other times its just useless strings.\n",
    "def find_numbers(s):\n",
    "    found = []\n",
    "    if len(re.findall('.*[0-9]+.*', s)) > 0:\n",
    "        found.append(re.findall('.*[0-9]+.*', s)[0])\n",
    "        return found[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "numbers = pd.Series(tokens).map(find_numbers)\n",
    "numbers = numbers[~numbers.isnull()]\n",
    "\n",
    "# there are strings with a lot of '*' in them. We need to remove these.\n",
    "def find_stars(s):\n",
    "    found = []\n",
    "    if len(re.findall('.*[\\*]+.*', s)) > 0:\n",
    "        found.append(re.findall('.*[\\*]+.*', s)[0])\n",
    "        return found[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "star_words = pd.Series(tokens).map(find_stars)\n",
    "star_words = star_words[star_words != 0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used the corpus to find out star words, urls, numbers, etc. in the text. We need to remove these from the fulldescription column.\n",
    "1. Remove the urls first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(s):\n",
    "    global weblinks\n",
    "    for i in weblinks:\n",
    "        s = s.replace(i, \"\")\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions'] = train['FullDescription'].map(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove the star_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_star_words(s):\n",
    "    global star_words\n",
    "    for i in star_words:\n",
    "        s = s.replace(i, \"\")\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions'] = train['Clean_Full_Descriptions'].map(remove_star_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(s):\n",
    "    global numbers\n",
    "    for i in numbers:\n",
    "        s = s.replace(i, \"\")\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions'] = train['Clean_Full_Descriptions'].map(remove_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Remove the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    global punctuation\n",
    "    for p in punctuation:\n",
    "        s = s.replace(p, '')\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions'] = train['Clean_Full_Descriptions'].map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Clean_Full_Descriptions'] = train['Clean_Full_Descriptions'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Clean_Full_Descriptions` has the full descriptions without punctuations, numbers, star words or urls!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "## Question A1 - \n",
    "###  Part 1 - What are the top 5 parts of speech in the job description? How frequently do they appear? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "We see that the most frequent parts of speech are -\n",
    "1. Noun (NN) - 156589\n",
    "2. Adjectives(JJ) - 70047\n",
    "3. Preposition (IN) - 65702\n",
    "4. Plural nouns(NNS) - 51286\n",
    "5. Determiner (DT) - 50691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach - \n",
    "1. Tokenize each description under the clean_full_description column.\n",
    "2. For each description get the parts of speech tagging for each string in the full description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN     156627\n",
       "JJ      70054\n",
       "IN      65701\n",
       "NNS     51287\n",
       "DT      50691\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for parts of speech tagging\n",
    "def pos_tagger(s):\n",
    "    \"\"\"For a given text description, tokenize the words in it, tag parts of speech and return just the tag\"\"\"\n",
    "    answer = []\n",
    "    text = word_tokenize(s)\n",
    "    answer.append(nltk.pos_tag(text))\n",
    "    answer_pos = [w for a in answer for (v,w) in a]\n",
    "    return answer_pos\n",
    "\n",
    "# map parts of speech to each description\n",
    "pos = train['Clean_Full_Descriptions'].map(pos_tagger)\n",
    "\n",
    "# get a list of all parts of speech found\n",
    "all_pos = []\n",
    "\n",
    "for a in pos:\n",
    "    for b in a:\n",
    "        all_pos.append(b)\n",
    "\n",
    "all_pos = pd.Series(all_pos)\n",
    "all_pos.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - How does the frequency change if we exclude stopwords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "We see that the most frequent parts of speech are -\n",
    "1. Noun (NN) - 151635\n",
    "2. Adjectives(JJ) - 72284\n",
    "3. Noun plural (NNS) - 50497\n",
    "4. Verb/Gerund(VBG) - 25118\n",
    "5. Verb/Present Participle (VBP) - 17218"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach -\n",
    "1. Remove stopwords from each of the descriptions.\n",
    "2. apply the pos_tagger again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN     151689\n",
       "JJ      72293\n",
       "NNS     50497\n",
       "VBG     25123\n",
       "VBP     17219\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store english stopwords in a list\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# define a function to remove stopwords from descriptions\n",
    "def remove_stopwords(s):\n",
    "    global en_stopwords\n",
    "    s = word_tokenize(s)\n",
    "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
    "    return s\n",
    "\n",
    "# Create a new column of descriptions with no stopwords\n",
    "train['Clean_Full_Descriptions_no_stop'] = train['Clean_Full_Descriptions'].map(remove_stopwords)\n",
    "\n",
    "# get parts of speech\n",
    "pos = train['Clean_Full_Descriptions_no_stop'].map(pos_tagger)\n",
    "\n",
    "# get a list of all parts of speech found\n",
    "all_pos = []\n",
    "\n",
    "for a in pos:\n",
    "    for b in a:\n",
    "        all_pos.append(b)\n",
    "\n",
    "all_pos = pd.Series(all_pos)\n",
    "all_pos.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question A2 - \n",
    "### Does this data support Zipf's law? Plot the 100 most common words in the data against the theoretical prediction of the law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach - \n",
    "1. Create a corpus of the cleaned descriptions.\n",
    "2. Tokenize the words in the corpus.\n",
    "3. Take a count of these words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer -\n",
    "Yes the data supports Zipf's law based on the top 100 most frequently occuring words. The theta value obtained from fitting the OLS on the log(frequency) to predict log(rank) is -1.03 which is close to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare corpus from the descriptions that still have stopwords\n",
    "corpus = \" \".join(train['Clean_Full_Descriptions'].tolist())\n",
    "\n",
    "#tokenize words\n",
    "tokenized_corpus = nltk.word_tokenize(corpus)\n",
    "fd = nltk.FreqDist(tokenized_corpus)\n",
    "\n",
    "# get the top words\n",
    "top_words = []\n",
    "for key, value in fd.items():\n",
    "    top_words.append((key, value))\n",
    "\n",
    "# sort the list by the top frequencies\n",
    "top_words = sorted(top_words, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "# keep top 100 words only\n",
    "top_words = top_words[:100]\n",
    "\n",
    "# Keep the frequencies only from the top word series\n",
    "top_word_series = pd.Series([w for (v,w) in top_words])\n",
    "top_word_series[:5]\n",
    "\n",
    "# get actual ranks of these words - wherever we see same frequencies, we give same rank\n",
    "word_ranks = top_word_series.rank(method = 'min', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of theta obtained is: [-1.03049236]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x267c5dd2f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run a regression on this\n",
    "denominator = max(word_ranks)*min(top_word_series)\n",
    "\n",
    "Y = np.array(np.log(word_ranks))\n",
    "X = np.array(np.log(top_word_series/denominator))\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg_model = linear_model.LinearRegression(fit_intercept = False)\n",
    "\n",
    "reg_model.fit(Y.reshape(-1,1), X)\n",
    "print(\"The value of theta obtained is:\",reg_model.coef_)\n",
    "\n",
    "# make a plot of actual vs theory\n",
    "plt.scatter(Y, X, label = \"Actual Rank vs Frequency\")\n",
    "plt.title('Log(Rank) vs Log(Frequency/nx(n))')\n",
    "plt.xlabel('Log Rank')\n",
    "plt.ylabel('Log(Frequency/nx(n))')\n",
    "\n",
    "plt.plot(reg_model.predict(X.reshape(-1,1)), X, color = 'red', label = \"Zipf's law\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question A3 - \n",
    "### If we remove stopwords and lemmatize the data, what are the 10 most common words? What are their frequencies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer - \n",
    "The top 10 words are - \n",
    "1. Experience - 4336\n",
    "2. Role - 3236\n",
    "3. team - 3018\n",
    "4. Work - 3015\n",
    "5. Client - 2859\n",
    "6. Business - 2857\n",
    "7. Skill - 2495\n",
    "8. Service - 2401\n",
    "9. Working - 2271\n",
    "10. Sale - 2234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 4336),\n",
       " ('role', 3236),\n",
       " ('team', 3018),\n",
       " ('work', 3015),\n",
       " ('client', 2859),\n",
       " ('business', 2857),\n",
       " ('skill', 2495),\n",
       " ('service', 2401),\n",
       " ('working', 2271),\n",
       " ('sale', 2234)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the necessary functions from the nltk library\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "# prepare corpus from the descriptions that still have stopwords\n",
    "corpus = \" \".join(train['Clean_Full_Descriptions_no_stop'].tolist())\n",
    "\n",
    "#tokenize words\n",
    "tokenized_corpus = nltk.word_tokenize(corpus)\n",
    "\n",
    "# lemmatize\n",
    "lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokenized_corpus]\n",
    "\n",
    "# word frequencies for the lemmatized tokens\n",
    "fd = nltk.FreqDist(lemmatized_tokens)\n",
    "\n",
    "# get the top words\n",
    "top_words = []\n",
    "for key, value in fd.items():\n",
    "    top_words.append((key, value))\n",
    "\n",
    "# sort the list by the top frequencies\n",
    "top_words = sorted(top_words, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "# keep top 100 words only\n",
    "top_words = top_words[:10]\n",
    "\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B\n",
    "## Question B1\n",
    "### Predict high (>75th percentile)/low (< 75th percentile) salary from just the numeric variables in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SalaryNormalized` has the salary values for each job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 75th percentile value of salary!\n",
    "sal_perc_75 = np.percentile(train['SalaryNormalized'], 75)\n",
    "\n",
    "# make a new target variable that captures whether salary is high (1) or low (0)\n",
    "train['Salary_Target'] = np.where(train['SalaryNormalized'] >= sal_perc_75, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most values in our dataframe are of the 'Object' or 'String' data type. This means that we will have to convert these to dummy variables to proceed!\n",
    "\n",
    "Let's first check for missing values in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContractType    1851\n",
       "ContractTime     653\n",
       "Company          328\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in the variables as shown above! These are all 'character' variables so when we create dummies, there will be a new column for the 'NA' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of expensive cities in England"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cities = ['London', 'Oxford', 'Brighton', 'Cambridge', 'Bristol', 'Portsmouth', 'Reading', 'Edinburgh', 'Leicester',\n",
    "             'York', 'Exeter']\n",
    "\n",
    "train['Exp_Location'] = np.where(train['LocationNormalized'].map(lambda x: x in exp_cities), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes using Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is: 0.78\n",
      "Area under the ROC curve: 0.589823330907166\n",
      "Confusion Matrix:\n",
      " [[363  18]\n",
      " [ 92  27]]\n"
     ]
    }
   ],
   "source": [
    "# Subset the columns required\n",
    "columns_required = ['ContractType', 'ContractTime', 'Company', 'Category', 'SourceName', 'Exp_Location', 'Salary_Target']\n",
    "\n",
    "train_b1 = train.loc[:, columns_required]\n",
    "\n",
    "# Convert the categorical variables to dummy variables\n",
    "train_b1 = pd.get_dummies(train_b1)\n",
    "\n",
    "# Lets separate the predictors from the target variable\n",
    "columns_selected = train_b1.columns.values.tolist()\n",
    "target_variable = ['Salary_Target']\n",
    "\n",
    "predictors = list(set(columns_selected) - set(target_variable))\n",
    "\n",
    "# setup the model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X = np.array(train_b1.loc[:,predictors])\n",
    "y = np.array(train_b1.loc[:,target_variable[0]])\n",
    "\n",
    "# create test train splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "# Fit the model and predict the output on the test data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted output\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy is:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer -\n",
    "#### The prediction accuracy achieved is 78% using just the numerical variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes using job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.826\n",
      "Area under the ROC curve: 0.7673636383687333\n",
      "Model Confusion Matrix:\n",
      " [[335  46]\n",
      " [ 41  78]]\n"
     ]
    }
   ],
   "source": [
    "# Lets lemmatize the job descriptions before we run the model\n",
    "def text_lemmatizer(s):\n",
    "    tokenized_corpus = nltk.word_tokenize(s)\n",
    "    \n",
    "    # lemmatize\n",
    "    s = \" \".join([lmtzr.lemmatize(token) for token in tokenized_corpus])\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions_no_stop_lemm'] = train['Clean_Full_Descriptions_no_stop'].map(text_lemmatizer)\n",
    "\n",
    "X = np.array(train.loc[:, 'Clean_Full_Descriptions_no_stop_lemm'])\n",
    "y = np.array(train.loc[:, 'Salary_Target'])\n",
    "\n",
    "# split into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "# Convert the arrays into a presence/absence matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_mult_model = MultinomialNB().fit(X_train_counts, y_train)\n",
    "predicted = nb_mult_model.predict(X_test_counts)\n",
    "\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes using Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.792\n",
      "Area under the ROC curve: 0.6208121043693068\n",
      "Model Confusion Matrix:\n",
      " [[361  20]\n",
      " [ 84  35]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequencies of words using the TfidfTransformer\n",
    "X_train_bern = np.where(X_train_counts.todense() > 0 , 1, 0)\n",
    "X_test_bern = np.where(X_test_counts.todense() > 0, 1, 0)\n",
    "\n",
    "# Fit the model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_bern_model = BernoulliNB().fit(X_train_bern, y_train)\n",
    "predicted = nb_bern_model.predict(X_test_bern)\n",
    "\n",
    "# print the accuracies\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words that indicate high/low salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the column names for the columns in our training dataset.\n",
    "column_names = [x for (x,y) in sorted(count_vectorizer.vocabulary_.items(), key = lambda x:x[1])]\n",
    "\n",
    "# probability of high salary\n",
    "p_1 = np.mean(y_train)\n",
    "\n",
    "# probability of low salary\n",
    "p_0 = 1 - p_1\n",
    "\n",
    "# create an array of feature vectors\n",
    "feature_vectors = np.array(X_train_bern)\n",
    "\n",
    "# probability of word appearance\n",
    "word_probabilities = np.mean(feature_vectors, axis = 0)\n",
    "\n",
    "# probability of seeing these words for class= 1 and class = 0 respectively\n",
    "p_x_1 = np.mean(feature_vectors[y_train==1, :], axis = 0)\n",
    "p_x_0 = np.mean(feature_vectors[y_train==0, :], axis = 0)\n",
    "\n",
    "# words that are good indicators of high salary (class = 1)\n",
    "high_indicators = p_x_1 * (np.log2(p_x_1) - np.log2(word_probabilities) - np.log2(p_1))\n",
    "\n",
    "high_indicators_series = pd.Series(high_indicators, index = column_names)\n",
    "\n",
    "# words that are good indicators of low salary (class = 0)\n",
    "low_indicators = p_x_0 * (np.log2(p_x_0) - np.log2(word_probabilities) - np.log2(p_0))\n",
    "\n",
    "low_indicators_series = pd.Series(low_indicators, index = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get words indicative of low salary\n",
    "The numbers against the terms show the mutual information of these words with the low salary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['experience', 'work', 'role', 'client', 'working', 'team', 'please',\n",
       "       'job', 'looking', 'skill'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_indicators_series[[i for i in low_indicators_series.index if i not in en_stopwords]].sort_values(ascending = False)[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get words indicative of high salary\n",
    "The numbers against the terms show the mutual information of these words with the low salary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['experience', 'role', 'team', 'business', 'opportunity', 'management',\n",
       "       'skill', 'client', 'work', 'project'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_indicators_series[[i for i in high_indicators_series.index if i not in en_stopwords]].sort_values(ascending = False)[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B3 - \n",
    "### Train a hybrid model to predict high/low salary using both numeric and text data. \n",
    "Show the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer - \n",
    "The accuracy of the model is 78.4%. Yes, given that just text descriptions give us 82.6% accuracy, we would have expected the hybrid model to outperform this but it didnt!\n",
    "\n",
    "We choose the text only model since it gives us the best accuracy out of sample!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is: 0.784\n",
      "Area under the ROC curve: 0.6328988288228679\n",
      "Confusion Matrix:\n",
      " [[351  30]\n",
      " [ 78  41]]\n"
     ]
    }
   ],
   "source": [
    "# convert text data to dataframe\n",
    "X = np.array(train.loc[:, 'Clean_Full_Descriptions_no_stop_lemm'])\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_counts = count_vectorizer.fit_transform(X)\n",
    "\n",
    "column_names = [x for (x,y) in sorted(count_vectorizer.vocabulary_.items(), key = lambda x:x[1])]\n",
    "X_counts_to_occurence = np.where(X_counts.todense() > 0, 1, 0)\n",
    "\n",
    "text_data = pd.DataFrame(X_counts_to_occurence, columns = column_names)\n",
    "\n",
    "# train_b1 has the numerical data we used earlier\n",
    "# Lets separate the predictors from the target variable\n",
    "columns_selected = train_b1.columns.values.tolist() + text_data.columns.values.tolist()\n",
    "\n",
    "target_variable = ['Salary_Target']\n",
    "\n",
    "predictors = list(set(columns_selected) - set(target_variable))\n",
    "\n",
    "full_data = pd.concat([train_b1, text_data], axis = 1)\n",
    "\n",
    "X = np.array(full_data.loc[:,predictors])\n",
    "y = np.array(full_data.loc[:,target_variable[0]])\n",
    "\n",
    "# create test train splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "# Fit the model and predict the output on the test data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted output\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy is:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
