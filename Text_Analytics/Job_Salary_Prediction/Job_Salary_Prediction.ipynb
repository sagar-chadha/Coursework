{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Salary Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kaggle competition challenges us to predict Job salaries based on job ads. The data provided has Job_Title, Location, Category, Contract Type, etc. \n",
    "\n",
    "Lets jump right in - \n",
    "1. Load the libraries required for this task.\n",
    "2. Read in the dataset.\n",
    "3. See what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the train_rev1 datafile downloaded from kaggle\n",
    "df = pd.read_csv('Train_rev1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244768 entries, 0 to 244767\n",
      "Data columns (total 12 columns):\n",
      "Id                    244768 non-null int64\n",
      "Title                 244767 non-null object\n",
      "FullDescription       244768 non-null object\n",
      "LocationRaw           244768 non-null object\n",
      "LocationNormalized    244768 non-null object\n",
      "ContractType          65442 non-null object\n",
      "ContractTime          180863 non-null object\n",
      "Company               212338 non-null object\n",
      "Category              244768 non-null object\n",
      "SalaryRaw             244768 non-null object\n",
      "SalaryNormalized      244768 non-null int64\n",
      "SourceName            244767 non-null object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has $244,768$ rows with 12 columns, most of which are text type columns as signified by the `object` data type. This means that we will have a large number of (0,1) type variables once the categorical columns are encoded. <br>\n",
    "\n",
    "In the interest of computation time (since I am doing this analysis on my laptop), I will randomly select 2500 rows to do the analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 2500 rows from the data\n",
    "import random\n",
    "random.seed(1) # so that results are reproducible\n",
    "\n",
    "# get a random sample of 2500 rows from the row indices\n",
    "indices = df.index.values.tolist()\n",
    "random_2500 = random.sample(indices, 2500)\n",
    "\n",
    "# subset the imported data on the selected 2500 indices\n",
    "train = df.loc[random_2500, :]\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some problems with the way FullDescription has been encoded\n",
    "def convert_utf8(s):\n",
    "    return str(s)\n",
    "\n",
    "train['FullDescription'] = train['FullDescription'].map(convert_utf8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68234454</td>\n",
       "      <td>Bar &amp; Leisure Supervisor</td>\n",
       "      <td>Genting Casinos UK is looking for an experienc...</td>\n",
       "      <td>Leicester Leicestershire East Midlands</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genting UK</td>\n",
       "      <td>Hospitality &amp; Catering Jobs</td>\n",
       "      <td>Up to 17,000 per annum</td>\n",
       "      <td>17000</td>\n",
       "      <td>caterer.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70762305</td>\n",
       "      <td>Principal Development Engineer</td>\n",
       "      <td>Principal Development Engineer  RF Microwave /...</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>ATA Recruitment</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>38000 - 45000/annum + 38k - 45k (DOE) + Pensio...</td>\n",
       "      <td>41500</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                           Title  \\\n",
       "0  68234454        Bar & Leisure Supervisor   \n",
       "1  70762305  Principal Development Engineer   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Genting Casinos UK is looking for an experienc...   \n",
       "1  Principal Development Engineer  RF Microwave /...   \n",
       "\n",
       "                              LocationRaw LocationNormalized ContractType  \\\n",
       "0  Leicester Leicestershire East Midlands          Leicester          NaN   \n",
       "1                                Scotland           Scotland          NaN   \n",
       "\n",
       "  ContractTime          Company                     Category  \\\n",
       "0          NaN       Genting UK  Hospitality & Catering Jobs   \n",
       "1    permanent  ATA Recruitment             Engineering Jobs   \n",
       "\n",
       "                                           SalaryRaw  SalaryNormalized  \\\n",
       "0                             Up to 17,000 per annum             17000   \n",
       "1  38000 - 45000/annum + 38k - 45k (DOE) + Pensio...             41500   \n",
       "\n",
       "         SourceName  \n",
       "0       caterer.com  \n",
       "1  cv-library.co.uk  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using text data is particularly tricky because of the large number of words, numbers, links, symbols, etc in it that is of no value to the prediction problem at hand. We need to manually clean the `FullDescription` column so that it is ready for our analysis. In particular, we carry out the following steps -  <br>\n",
    "\n",
    "**Step 1:** *Make a corpus of all the descriptions provided to us.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a corpus of all the words in the job description\n",
    "corpus = \". \".join(train['FullDescription'].tolist())\n",
    "\n",
    "# tokenize the corpus to get individual words\n",
    "tokens = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** *From this corpus, we will pick up anomalies in the descriptions - urls, numbers, etc. that are of no use to us in terms of predictions.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all urls in the data\n",
    "weblinks = [w for w in tokens if \".co.uk\" in w] + [w for w in tokens if \".com\" in w] + [w for w in tokens if \"www\" in w]\n",
    "weblinks = list(set(weblinks)) # remove duplicates from weblinks\n",
    "\n",
    "# We also notice a lot of words with '*' characters in them. These are sometimes salary figures that have been hidden to \n",
    "# keep the prediction problem meaningful. Other times its just useless strings.\n",
    "def find_numbers(s):\n",
    "    found = []\n",
    "    if len(re.findall('.*[0-9]+.*', s)) > 0:\n",
    "        found.append(re.findall('.*[0-9]+.*', s)[0])\n",
    "        return found[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "numbers = pd.Series(tokens).map(find_numbers)\n",
    "numbers = numbers[~numbers.isnull()]\n",
    "\n",
    "# there are strings with a lot of '*' in them. We need to remove these.\n",
    "def find_stars(s):\n",
    "    found = []\n",
    "    if len(re.findall('.*[\\*]+.*', s)) > 0:\n",
    "        found.append(re.findall('.*[\\*]+,*', s)[0])\n",
    "        return found[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "star_words = pd.Series(tokens).map(find_stars)\n",
    "star_words = star_words[star_words != 0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many urls, numbers and star_words are found in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urls found: 1098\n",
      "Numbers found: 3814\n",
      "Star words found: 7180\n"
     ]
    }
   ],
   "source": [
    "print(\"Urls found:\",len(weblinks))\n",
    "print(\"Numbers found:\", len(numbers))\n",
    "print(\"Star words found:\", len(star_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** *Going back to our dataset, we will clean the descriptions by removing these anomalous strings from the job descriptions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# remove urls, starwords, numbers and punctuations\n",
    "def remove_anomalous_string(s):\n",
    "    global weblinks, star_words, numbers, punctuation\n",
    "    for i in weblinks:\n",
    "        s = s.replace(i, \"\")\n",
    "\n",
    "    for j in star_words:\n",
    "        s = s.replace(j, \"\")\n",
    "        \n",
    "    for k in numbers:\n",
    "        s = s.replace(k, \"\")\n",
    "        \n",
    "    for l in punctuation:\n",
    "        s = s.replace(l, \"\")\n",
    "\n",
    "    return s\n",
    "\n",
    "train['Clean_Full_Descriptions'] = train['FullDescription'].map(remove_anomalous_string).map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** *Finally, lets remove stopwords from our descriptions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store english stopwords in a list\n",
    "from nltk.corpus import stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# define a function to remove stopwords from descriptions\n",
    "def remove_stopwords(s):\n",
    "    global en_stopwords\n",
    "    s = word_tokenize(s)\n",
    "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
    "    return s\n",
    "\n",
    "# Create a new column of descriptions with no stopwords\n",
    "train['Clean_Full_Descriptions_no_stop'] = train['Clean_Full_Descriptions'].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Clean_Full_Descriptions_no_stop` has the full descriptions without punctuations, numbers, star words, urls or stopwords!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets lemmatize the text to remove excess forms of the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lemm = WordNetLemmatizer()\n",
    "\n",
    "def convert_to_valid_pos(x):\n",
    "    \n",
    "    x = x[0].upper() # extract first character of the POS tag\n",
    "    \n",
    "    # define mapping for the tag to correct tag.\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "               \"N\": wordnet.NOUN,\n",
    "               \"R\": wordnet.ADV,\n",
    "               \"V\": wordnet.VERB}\n",
    "    \n",
    "    return tag_dict.get(x, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(s):\n",
    "    pos_tagged_text = nltk.pos_tag(word_tokenize(s))\n",
    "    \n",
    "    lemm_list = []\n",
    "\n",
    "    for (word, tag) in pos_tagged_text:\n",
    "        lemm_list.append(word_lemm.lemmatize(word, pos = convert_to_valid_pos(tag)))\n",
    "\n",
    "\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "    return lemm_text\n",
    "\n",
    "train['Clean_Full_Descriptions_no_stop'] = train['Clean_Full_Descriptions_no_stop'].map(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of expensive cities in England\n",
    "\n",
    "`LocationNormalized` has the locations for the jobs. If a city is expensive to live in, I presume that salaries on average would be higher there. This could be an important predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cities = ['London', 'Oxford', 'Brighton', 'Cambridge', 'Bristol', 'Portsmouth', \n",
    "              'Reading', 'Edinburgh', 'Leicester', 'York', 'Exeter']\n",
    "\n",
    "train['Exp_Location'] = np.where(train['LocationNormalized'].map(lambda x: x in exp_cities), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the target Variable\n",
    "\n",
    "`SalaryNormalized` has the salary values for each job description. We need to create a new categorical variable based off of this that has the value $1$ if salary value is greater than or equal to the $75^{th}$ percentile or $0$ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 75th percentile value of salary!\n",
    "sal_perc_75 = np.percentile(train['SalaryNormalized'], 75)\n",
    "\n",
    "# make a new target variable that captures whether salary is high (1) or low (0)\n",
    "train['Salary_Target'] = np.where(train['SalaryNormalized'] >= sal_perc_75, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most values in our dataframe are of the 'Object' or 'String' data type. This means that we will have to convert these to dummy variables to proceed!\n",
    "\n",
    "Let's first check for missing values in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContractType    1851\n",
       "ContractTime     653\n",
       "Company          328\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values in the variables as shown above! I will not try to impute the most frequent category, instead I will proceed with encoding these and hence there will be a new column for the 'NA' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the columns required\n",
    "columns_required = ['ContractType', 'ContractTime', 'Company', 'Category', 'SourceName', 'Exp_Location', 'Salary_Target']\n",
    "\n",
    "train_b1 = train.loc[:, columns_required]\n",
    "\n",
    "# Convert the categorical variables to dummy variables\n",
    "train_b1 = pd.get_dummies(train_b1)\n",
    "\n",
    "# Lets separate the predictors from the target variable\n",
    "columns_selected = train_b1.columns.values.tolist()\n",
    "target_variable = ['Salary_Target']\n",
    "\n",
    "predictors = list(set(columns_selected) - set(target_variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "\n",
    "#### Approach 1: Predict using variables other than job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model:** *Bernoulli Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is: 0.78\n",
      "Area under the ROC curve: 0.589823330907166\n",
      "Confusion Matrix:\n",
      " [[363  18]\n",
      " [ 92  27]]\n"
     ]
    }
   ],
   "source": [
    "# setup the model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X = np.array(train_b1.loc[:,predictors])\n",
    "y = np.array(train_b1.loc[:,target_variable[0]])\n",
    "\n",
    "# create test train splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "# Fit the model and predict the output on the test data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted output\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy is:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy is 78% using the categorical variables. Let's see what we get if we use job descriptions! Since this is a rare class problem, the AUROC score is more important and its just 0.59 which means very close to a random classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: Predict using the job descriptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1:** *Bernoulli Naive Bayes* <br>\n",
    "Bernoulli naive bayes is most suited for small documents since it only considers appearance/absence of terms. Let's test it anyway on the data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.786\n",
      "Area under the ROC curve: 0.6110964070667636\n",
      "Model Confusion Matrix:\n",
      " [[360  21]\n",
      " [ 86  33]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequencies of words using the TfidfTransformer\n",
    "X = np.array(train.loc[:, 'Clean_Full_Descriptions_no_stop'])\n",
    "y = np.array(train.loc[:, 'Salary_Target'])\n",
    "\n",
    "# split into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "# Convert the arrays into a presence/absence matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_bern = np.where(X_train_counts.todense() > 0 , 1, 0)\n",
    "X_test_bern = np.where(X_test_counts.todense() > 0, 1, 0)\n",
    "\n",
    "# Fit the model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_bern_model = BernoulliNB().fit(X_train_bern, y_train)\n",
    "predicted = nb_bern_model.predict(X_test_bern)\n",
    "\n",
    "# print the accuracies\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2:** *Multinomial Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.834\n",
      "Area under the ROC curve: 0.7697236374864906\n",
      "Model Confusion Matrix:\n",
      " [[340  41]\n",
      " [ 42  77]]\n"
     ]
    }
   ],
   "source": [
    "# lets use the lemmatized descriptions to fit the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_mult_model = MultinomialNB().fit(X_train_counts, y_train)\n",
    "predicted = nb_mult_model.predict(X_test_counts)\n",
    "\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3:** *Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(class_weight = \"balanced\")\n",
    "\n",
    "log_reg.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.834\n",
      "Area under the ROC curve: 0.7552769139151724\n",
      "Model Confusion Matrix:\n",
      " [[345  36]\n",
      " [ 47  72]]\n"
     ]
    }
   ],
   "source": [
    "predicted = log_reg.predict(X_test_counts)\n",
    "\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 4:** *Support Vector Machines*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel = \"rbf\", gamma = \"auto\", C = 100, random_state = 42, class_weight = \"balanced\")\n",
    "\n",
    "svm_clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.838\n",
      "Area under the ROC curve: 0.7694589646882375\n",
      "Model Confusion Matrix:\n",
      " [[343  38]\n",
      " [ 43  76]]\n"
     ]
    }
   ],
   "source": [
    "predicted = svm_clf.predict(X_test_counts)\n",
    "\n",
    "print(\"Model Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Model Confusion Matrix:\\n\", metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM method has the most accuracy for prediction of the salaries! Its AUROC score is just under that of Multinomial Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words that indicate high/low salary\n",
    "\n",
    "Mutual information measures how much information a particular token contains about the class. Essentially, this is saying something like this- ‘Knowing that this token appears in the document how much can we say about what class this is from’. Let's see which words have the most predictive power for high and low salary classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the column names for the columns in our training dataset.\n",
    "column_names = [x for (x,y) in sorted(count_vectorizer.vocabulary_.items(), key = lambda x:x[1])]\n",
    "\n",
    "# probability of high salary\n",
    "p_1 = np.mean(y_train)\n",
    "\n",
    "# probability of low salary\n",
    "p_0 = 1 - p_1\n",
    "\n",
    "# create an array of feature vectors\n",
    "feature_vectors = np.array(X_train_bern)\n",
    "\n",
    "# probability of word appearance\n",
    "word_probabilities = np.mean(feature_vectors, axis = 0)\n",
    "\n",
    "# probability of seeing these words for class= 1 and class = 0 respectively\n",
    "p_x_1 = np.mean(feature_vectors[y_train==1, :], axis = 0)\n",
    "p_x_0 = np.mean(feature_vectors[y_train==0, :], axis = 0)\n",
    "\n",
    "# words that are good indicators of high salary (class = 1)\n",
    "high_indicators = p_x_1 * (np.log2(p_x_1) - np.log2(word_probabilities) - np.log2(p_1))\n",
    "\n",
    "high_indicators_series = pd.Series(high_indicators, index = column_names)\n",
    "\n",
    "# words that are good indicators of low salary (class = 0)\n",
    "low_indicators = p_x_0 * (np.log2(p_x_0) - np.log2(word_probabilities) - np.log2(p_0))\n",
    "\n",
    "low_indicators_series = pd.Series(low_indicators, index = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words indicative of low salary\n",
    "The numbers against the terms show the mutual information of these words with the low salary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['work', 'experience', 'role', 'client', 'team', 'look', 'please', 'job',\n",
       "       'apply', 'skill'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_indicators_series[[i for i in low_indicators_series.index]].\\\n",
    "sort_values(ascending = False)[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words indicative of high salary\n",
    "The numbers against the terms show the mutual information of these words with the low salary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['experience', 'work', 'role', 'business', 'team', 'lead', 'opportunity',\n",
       "       'management', 'client', 'project'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_indicators_series[[i for i in high_indicators_series.index]].\\\n",
    "sort_values(ascending = False)[:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: Predict using all variables\n",
    "\n",
    "**Model:** *Bernoulli Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is: 0.774\n",
      "Area under the ROC curve: 0.6147797701757868\n",
      "Confusion Matrix:\n",
      " [[350  31]\n",
      " [ 82  37]]\n"
     ]
    }
   ],
   "source": [
    "# convert text data to dataframe\n",
    "X = np.array(train.loc[:, 'Clean_Full_Descriptions_no_stop'])\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_counts = count_vectorizer.fit_transform(X)\n",
    "\n",
    "column_names = [x for (x,y) in sorted(count_vectorizer.vocabulary_.items(), key = lambda x:x[1])]\n",
    "X_counts_to_occurence = np.where(X_counts.todense() > 0, 1, 0)\n",
    "\n",
    "text_data = pd.DataFrame(X_counts_to_occurence, columns = column_names)\n",
    "\n",
    "# train_b1 has the numerical data we used earlier\n",
    "# Lets separate the predictors from the target variable\n",
    "columns_selected = train_b1.columns.values.tolist() + text_data.columns.values.tolist()\n",
    "\n",
    "target_variable = ['Salary_Target']\n",
    "\n",
    "predictors = list(set(columns_selected) - set(target_variable))\n",
    "\n",
    "full_data = pd.concat([train_b1, text_data], axis = 1)\n",
    "\n",
    "X = np.array(full_data.loc[:,predictors])\n",
    "y = np.array(full_data.loc[:,target_variable[0]])\n",
    "\n",
    "# create test train splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "# Fit the model and predict the output on the test data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted output\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy is:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is: 0.832\n",
      "Area under the ROC curve: 0.7741899909570128\n",
      "Confusion Matrix:\n",
      " [[337  44]\n",
      " [ 40  79]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C = 0.1, class_weight = \"balanced\")\n",
    "\n",
    "# Fit the model and predict the output on the test data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicted output\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy is:\", metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Area under the ROC curve:\", metrics.roc_auc_score(y_test, predicted))\n",
    "print(\"Confusion Matrix:\\n\",metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 0.832%. AUROC score is at 0.77 which is the highest we have obtained so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that job descriptions are very effective in helping predict job salaries. I achieved an accuracy of 83.8% when using just job descriptions with an AUROC score of 0.769. This was slightly higher than the value of 78.6% when using predictors other than job descriptions. I was surprised to find that the final model (where I used all variables) didn't perform much better, it performed only slightly better!\n",
    "\n",
    "With mutual information, the results were interesting - <br>\n",
    "All jobs have a mention of experience, role and work <br>\n",
    "Higher salaried jobs mention terms like *business*, *management*, *lead*, etc. <br>\n",
    "Lower salaried jobs mention terms like *job*, *skill*, *apply*, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
